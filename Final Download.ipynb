{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yazdsous\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#WHERE WE EXTRACT TABLE NAME FROM CSV\n",
    "from bs4 import BeautifulSoup\n",
    "from tika import parser\n",
    "import os\n",
    "import re\n",
    "import camelot\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################FUNCTIONS##################################################\n",
    "def get_table_titles(page:int, df:pd.DataFrame) -> list():#pd.DataFrame:\n",
    "    tbl_names = list()\n",
    "    tbl_names = list(df[df['page_number']== page]['final_table_title'])\n",
    "                \n",
    "    return tbl_names\n",
    "#********************************************************************************#\n",
    "def replace_chars(text:str) -> str:\n",
    "    chars_0 = ['\\n',':']\n",
    "    chars_1 = ['/','\\\\']\n",
    "    for c in chars_0:\n",
    "        text = text.replace(c, ' ')\n",
    "    for cc in chars_1:\n",
    "        text = text.replace(cc,'_')\n",
    "    return text\n",
    "#********************************************************************************#\n",
    "def replace_chars_strings(lst:list) -> list:\n",
    "    new_lst = []\n",
    "    for itm in lst:\n",
    "        new_lst.append(replace_chars(itm))       \n",
    "    return new_lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Function\n",
    "def extract_tables(file:str(),df:pd.DataFrame):    \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    file_path = 'F:/Environmental Baseline Data/Version 4 - Final/PDF/{}'.format(file)\n",
    "\n",
    "    file_name = file_path.split('/')[-1].replace('.pdf','')\n",
    "\n",
    "    data = parser.from_file(file_path,xmlContent=True)\n",
    "    #raw_xml = parser.from_file('A6T2V6.pdf', xmlContent=True)\n",
    "\n",
    "    #xml tag <div> splitting point for pages\n",
    "    soup = BeautifulSoup(data['content'], 'lxml')\n",
    "    pages = soup.find_all('div', attrs={'class': 'page'})\n",
    "\n",
    "    title_dict = dict()\n",
    "    start_time = datetime.now()\n",
    "    for ind, page in enumerate (pages):\n",
    "        pg_num = ind\n",
    "        chars = []\n",
    "        #camelot table objects for each page of the pdf\n",
    "        try:\n",
    "            tables = camelot.read_pdf(file_path, pages = str(pg_num+1), flag_size=True, copy_text=['v'],strip_text = '\\n',line_scale=40, f = 'csv',flavour = 'stream')  #loop len(tables)\n",
    "        except:\n",
    "            continue\n",
    "        #get table names in page == pg_num by parsing get_table_titles() function\n",
    "        title_lst_raw = get_table_titles(pg_num+1,df)\n",
    "        title_lst = replace_chars_strings(title_lst_raw)\n",
    "        #get total number of table objects detected by Camelot in page == pg_num\n",
    "        tb_num = tables.n\n",
    "\n",
    "        #VIEW\n",
    "        print(title_lst)  \n",
    "        #if Camelot returns NO table on the page continue the loop and go to the next page\n",
    "        if tb_num == 0:\n",
    "            print(\"No table on page \"+ str(pg_num+1) + \" is detected\")\n",
    "            continue\n",
    "        #if whitespace of the detected table is larger than 69% of the entire table and there is only\n",
    "        #one table on that page, identify this as figure and continute the loop and go to the next page\n",
    "        elif tb_num == 1 and (tables[0].parsing_report)['whitespace'] > 69.0:\n",
    "            print(\"Page {} contains an image\".format((tables[0].parsing_report)['page'] ))  \n",
    "            continue\n",
    "        #in case only one table is present on the page,\n",
    "        elif tb_num == 1:\n",
    "            #this block distills the dataframe with proper column names\n",
    "            df_tb = tables[0].df\n",
    "            df_tb = df_tb.replace('/na', '_', regex = True)\n",
    "            colname = df_tb.iloc[0].str.replace('\\n',' ',regex=True)\n",
    "            df_tb.columns = colname\n",
    "            df_tb = df_tb[1:]   \n",
    "            #df_tb = df_tb.iloc[1:]\n",
    "            #in case no title is extracted from this page but we know that there is one table\n",
    "            if len(title_lst) == 0:\n",
    "                #let's say we are on page number x and this if statement checks whether page number x-1 contianed a table or not\n",
    "                #if the result is TRUE we assign the title of last table on previous page to this page's title-less table\n",
    "                if (pg_num-1 in title_dict):\n",
    "                    #find the list of tables on the previous page\n",
    "                    lst_tbl = (title_dict.get(pg_num-1))[-1]\n",
    "                    lst_tbl_df = lst_tbl[1]\n",
    "                    #find similarity score of column names of table on page x and page x-1\n",
    "                    col_concat_curr = list(df_tb.columns.values)\n",
    "                    ccc = ''.join(col_concat_curr)\n",
    "                    col_join_curr = (ccc.replace(' ','')).replace('\\n','')\n",
    "                    col_concat_prev = list(lst_tbl_df.columns.values)\n",
    "                    ccp = ''.join(col_concat_prev)\n",
    "                    col_join_prev = (ccp.replace(' ','')).replace('\\n','')  \n",
    "                    ratio_similarity = fuzz.token_sort_ratio(col_join_curr, col_join_prev)\n",
    "                    #check if the columns of the last table on the previous page are the same as the table on this page\n",
    "                    if (len((set(lst_tbl_df.columns)).difference(set(df_tb.columns))) == 0) or (len(set(lst_tbl_df.columns))== len(set(df_tb.columns))) or (ratio_similarity > 89):\n",
    "                        xl_name = lst_tbl[2]\n",
    "                        chars.append([0,df_tb,xl_name])\n",
    "                        xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                        df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')     \n",
    "                    else:\n",
    "                        xl_name = file_name\n",
    "                        chars.append([0,df_tb,xl_name])\n",
    "                        xlsx_name = file_name + '_' +str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                        df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "                    title_dict[pg_num] = chars\n",
    "\n",
    "                else:\n",
    "                    xl_name = file_name       \n",
    "                    chars.append([0,df_tb,xl_name])\n",
    "                    xlsx_name = file_name + '_' +str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                    df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "                    title_dict[pg_num] = chars\n",
    "            else:\n",
    "                xl_name = title_lst[0]\n",
    "    #                xl_name = xl_name.replace('/','_')\n",
    "    #                xl_name = xl_name.replace(':','')\n",
    "                #store page number, index of the table, and its name in a dictionary\n",
    "                chars.append([0,df_tb,xl_name])\n",
    "                xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "                title_dict[pg_num] = chars\n",
    "\n",
    "        else:\n",
    "            if len(title_lst) >= tb_num :\n",
    "                for j in range(0,tb_num):\n",
    "                    df_tb = tables[j].df\n",
    "                    df_tb = df_tb.replace('/na', '_', regex = True)\n",
    "                    df_tb.columns = df_tb.iloc[0].str.replace('\\n',' ',regex=True)\n",
    "                    df_tb = df_tb[1:]\n",
    "                    #df_tb = df_tb.iloc[1:]\n",
    "                    xl_name = title_lst[j]\n",
    "    #                    xl_name = xl_name.replace('/','_')\n",
    "    #                    xl_name = xl_name.replace(':','')\n",
    "\n",
    "                    #store page number, index of the table, and its name in a dictionary\n",
    "                    chars.append([j,df_tb,xl_name])\n",
    "\n",
    "                    xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(j+1)+ '.csv'\n",
    "                    df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "\n",
    "                title_dict[pg_num] = chars\n",
    "\n",
    "            elif len(title_lst) < tb_num :\n",
    "                try:\n",
    "                    #first case: if the first table in the page is conitnuos of what was on the previous page\n",
    "                    df_tb = tables[0].df\n",
    "                    df_tb = df_tb.replace('/na', '_', regex = True)\n",
    "                    df_tb.columns = df_tb.iloc[0].str.replace('\\n',' ',regex=True)\n",
    "                    df_tb = df_tb[1:]\n",
    "                    #df_tb = df_tb.iloc[1:]\n",
    "\n",
    "                    if (pg_num-1 in title_dict):\n",
    "                        #find the list of tables on the previous page\n",
    "                        lst_tbl = (title_dict.get(pg_num-1))[-1]\n",
    "                        lst_tbl_df = lst_tbl[1]\n",
    "                        #check if the columns of the last table on the previous page are the same as the table on this page\n",
    "\n",
    "                        col_concat_curr = list(df_tb.columns.values)\n",
    "                        ccc = ''.join(col_concat_curr)\n",
    "                        col_join_curr = (ccc.replace(' ','')).replace('\\n','')\n",
    "                        col_concat_prev = list(lst_tbl_df.columns.values)\n",
    "                        ccp = ''.join(col_concat_prev)\n",
    "                        col_join_prev = (ccp.replace(' ','')).replace('\\n','')  \n",
    "                        ratio_similarity = fuzz.token_sort_ratio(ccc, ccp)\n",
    "\n",
    "                        if len((set(lst_tbl_df.columns)).difference(set(df_tb.columns))) == 0 or len(set(lst_tbl_df.columns))== len(set(df_tb.columns)) or ratio_similarity > 89:\n",
    "                            xl_name = lst_tbl[2]                           \n",
    "                            chars.append([0,df_tb,xl_name])                         \n",
    "                            xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                            df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "\n",
    "                        else:\n",
    "                            xl_name = file_name   \n",
    "                            chars.append([0,df_tb,xl_name])\n",
    "                            xlsx_name = file_name + '_' +str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                            df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "                    else:\n",
    "                        xl_name = file_name       \n",
    "                        chars.append([0,df_tb,xl_name])\n",
    "                        xlsx_name = file_name + '_' +str(pg_num+1)+'_'+str(1)+ '.csv'\n",
    "                        df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "\n",
    "                    indx = 0\n",
    "                    for j in range(1,len(title_lst)+1):\n",
    "                        df_tb = tables[j].df\n",
    "                        df_tb = df_tb.replace('/na', '_', regex = True)\n",
    "                        df_tb.columns = df_tb.iloc[0].str.replace('\\n',' ',regex=True)\n",
    "                        df_tb = df_tb[1:]\n",
    "                        #df_tb = df_tb.iloc[1:]\n",
    "                        xl_name = title_lst[indx]\n",
    "                        indx = indx + 1\n",
    "    #                        xl_name = xl_name.replace('/','_')\n",
    "    #                        xl_name = xl_name.replace(':','')\n",
    "                        #store page number, index of the table, and its name in a dictionary\n",
    "                        chars.append([j,df_tb,xl_name])\n",
    "\n",
    "                        xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(j+1)+ '.csv'\n",
    "                        #xlsx_name = z.split('\\\\')[-1] + '-' + str(pg[i]+1) + str(j) + '.xlsx'\n",
    "                        df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')\n",
    "\n",
    "                    for j in range(len(title_lst)+1,tb_num):\n",
    "                        df_tb = tables[j].df\n",
    "                        df_tb = df_tb.replace('/na', '_', regex = True)\n",
    "                        df_tb.columns = df_tb.iloc[0].str.replace('\\n',' ',regex=True)\n",
    "                        df_tb = df_tb[1:]\n",
    "                        #df_tb = df_tb.iloc[1:]\n",
    "                        xl_name = file_name\n",
    "                        #store page number, index of the table, and its name in a dictionary\n",
    "                        chars.append([j,df_tb,xl_name])                        \n",
    "\n",
    "                        xlsx_name = file_name + '_' + xl_name +'_'+str(pg_num+1)+'_'+str(j+1)+ '.csv'\n",
    "                        #xlsx_name = z.split('\\\\')[-1] + '-' + str(pg[i]+1) + str(j) + '.xlsx'\n",
    "                        df_tb.to_csv(xlsx_name, index = False, encoding='utf-8-sig')                    \n",
    "                    title_dict[pg_num] = chars\n",
    "\n",
    "                except:\n",
    "                    print(\"Function failed on page {}\".format(pg_num+1))\n",
    "                    pass\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print('Duration: {}'.format(end_time - start_time))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>final_table_title</th>\n",
       "      <th>categories</th>\n",
       "      <th>DataID_pdf</th>\n",
       "      <th>Application title short</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Table 1 Hydrometric Data From Discharge Statio...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1059614.pdf</td>\n",
       "      <td>Application for North Montney Project</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Table 2 Fish Species That May Occur In The Upp...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1059614.pdf</td>\n",
       "      <td>Application for North Montney Project</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Table 3 Summary Of Aquatics Field Work And Abo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1059614.pdf</td>\n",
       "      <td>Application for North Montney Project</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>Table 4 Summary Of Watercourse Crossings Along...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1059614.pdf</td>\n",
       "      <td>Application for North Montney Project</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>Table 4 Summary Of Watercourse Crossings Along...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1059614.pdf</td>\n",
       "      <td>Application for North Montney Project</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                  final_table_title  categories  \\\n",
       "2            8  Table 1 Hydrometric Data From Discharge Statio...        0.75   \n",
       "3            9  Table 2 Fish Species That May Occur In The Upp...        0.75   \n",
       "4           14  Table 3 Summary Of Aquatics Field Work And Abo...        0.75   \n",
       "5           17  Table 4 Summary Of Watercourse Crossings Along...        0.75   \n",
       "6           18  Table 4 Summary Of Watercourse Crossings Along...        0.35   \n",
       "\n",
       "    DataID_pdf                Application title short Category  \n",
       "2  1059614.pdf  Application for North Montney Project    Table  \n",
       "3  1059614.pdf  Application for North Montney Project    Table  \n",
       "4  1059614.pdf  Application for North Montney Project    Table  \n",
       "5  1059614.pdf  Application for North Montney Project    Table  \n",
       "6  1059614.pdf  Application for North Montney Project    Table  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'F:/Environmental Baseline Data/Version 4 - Final/Support files/Table titles raw data/final_table_titles2.csv'\n",
    "df = pd.read_csv(path, usecols = ['page_number','final_table_title', 'Application title short', 'DataID_pdf', \\\n",
    "                                  'categories', 'Category'])\n",
    "df = df[df['categories'] > 0] \n",
    "df = df[df['Category'] == 'Table']\n",
    "df['final_table_title'] = df['final_table_title'].str.title()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application for 2021 NGTL System Expansion Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>final_table_title</th>\n",
       "      <th>categories</th>\n",
       "      <th>DataID_pdf</th>\n",
       "      <th>Application title short</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Table 5.1–1: Physical And Meteorological Data ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3578647.pdf</td>\n",
       "      <td>Application for 2021 NGTL System Expansion Pro...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Table 5.1–2: Biophysical Regions In Project Area</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3578647.pdf</td>\n",
       "      <td>Application for 2021 NGTL System Expansion Pro...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Table 5.1–3: Uppermost Bedrock Formation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3578647.pdf</td>\n",
       "      <td>Application for 2021 NGTL System Expansion Pro...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Table 5.1–4: Surficial Geology</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3578647.pdf</td>\n",
       "      <td>Application for 2021 NGTL System Expansion Pro...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Table 5.1–5: Stations Used To Provide Climate ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3578647.pdf</td>\n",
       "      <td>Application for 2021 NGTL System Expansion Pro...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                  final_table_title  categories  \\\n",
       "0            3  Table 5.1–1: Physical And Meteorological Data ...         1.0   \n",
       "1            4   Table 5.1–2: Biophysical Regions In Project Area         1.0   \n",
       "2            6           Table 5.1–3: Uppermost Bedrock Formation         1.0   \n",
       "3            7                     Table 5.1–4: Surficial Geology         1.0   \n",
       "4           10  Table 5.1–5: Stations Used To Provide Climate ...         1.0   \n",
       "\n",
       "    DataID_pdf                            Application title short Category  \n",
       "0  3578647.pdf  Application for 2021 NGTL System Expansion Pro...    Table  \n",
       "1  3578647.pdf  Application for 2021 NGTL System Expansion Pro...    Table  \n",
       "2  3578647.pdf  Application for 2021 NGTL System Expansion Pro...    Table  \n",
       "3  3578647.pdf  Application for 2021 NGTL System Expansion Pro...    Table  \n",
       "4  3578647.pdf  Application for 2021 NGTL System Expansion Pro...    Table  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hearing = 'Application for 2021 NGTL System Expansion Project' \n",
    "ngtl2021 = df[df['Application title short'] == hearing].reset_index(drop = True)\n",
    "ngtl2021.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this folder to the path were you want the tables saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'H:\\GitHub\\tmp\\A_p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the dataframe name accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3578647.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = ngtl2021['DataID_pdf'][0]\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call the main function -- pass filename and dataframe as function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "No table on page 1 is detected\n",
      "[]\n",
      "No table on page 2 is detected\n",
      "['Table 5.1–1  Physical And Meteorological Data Sources']\n",
      "['Table 5.1–2  Biophysical Regions In Project Area']\n",
      "[]\n",
      "Page 5 contains an image\n",
      "['Table 5.1–3  Uppermost Bedrock Formation']\n",
      "['Table 5.1–4  Surficial Geology', 'Table 11.1–1  Wildlife Species Selected For Detailed Assessment And Selection Rationale', 'Table 12.1–1  Wildlife Species Selected For Assessment And Selection Rationale']\n"
     ]
    }
   ],
   "source": [
    "extract_tables(file,ngtl2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application for the 2017 NGTL System Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>final_table_title</th>\n",
       "      <th>categories</th>\n",
       "      <th>DataID_pdf</th>\n",
       "      <th>Application title short</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Table 8C.1 Cumulative Effects Characterization...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2748265.pdf</td>\n",
       "      <td>Application for the 2017 NGTL System Expansion</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Table 8C.2 Cumulative Effects Characterization...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2748265.pdf</td>\n",
       "      <td>Application for the 2017 NGTL System Expansion</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Table 8C.2 Cumulative Effects Characterization...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2748265.pdf</td>\n",
       "      <td>Application for the 2017 NGTL System Expansion</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Table 8C.3 Cumulative Effects Characterization...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2748265.pdf</td>\n",
       "      <td>Application for the 2017 NGTL System Expansion</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Table 8C.3 Cumulative Effects Characterization...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2748265.pdf</td>\n",
       "      <td>Application for the 2017 NGTL System Expansion</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                  final_table_title  categories  \\\n",
       "0            6  Table 8C.1 Cumulative Effects Characterization...        0.75   \n",
       "1            7  Table 8C.2 Cumulative Effects Characterization...        0.75   \n",
       "2            8  Table 8C.2 Cumulative Effects Characterization...        0.35   \n",
       "3            9  Table 8C.3 Cumulative Effects Characterization...        0.75   \n",
       "4           10  Table 8C.3 Cumulative Effects Characterization...        0.35   \n",
       "\n",
       "    DataID_pdf                         Application title short Category  \n",
       "0  2748265.pdf  Application for the 2017 NGTL System Expansion    Table  \n",
       "1  2748265.pdf  Application for the 2017 NGTL System Expansion    Table  \n",
       "2  2748265.pdf  Application for the 2017 NGTL System Expansion    Table  \n",
       "3  2748265.pdf  Application for the 2017 NGTL System Expansion    Table  \n",
       "4  2748265.pdf  Application for the 2017 NGTL System Expansion    Table  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hearing = 'Application for the 2017 NGTL System Expansion'\n",
    "ngtl2017 = df[df['Application title short'] == hearing].reset_index(drop = True)\n",
    "ngtl2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application for Northwest Mainline Komie North Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>final_table_title</th>\n",
       "      <th>categories</th>\n",
       "      <th>DataID_pdf</th>\n",
       "      <th>Application title short</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Table 1 Summary Of Identified Residual Project...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729032.pdf</td>\n",
       "      <td>Application for Northwest Mainline Komie North...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Table 1 Summary Of Identified Residual Project...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729032.pdf</td>\n",
       "      <td>Application for Northwest Mainline Komie North...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Table 1 Summary Of Identified Residual Project...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729032.pdf</td>\n",
       "      <td>Application for Northwest Mainline Komie North...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Table 1 Summary Of Identified Residual Project...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729032.pdf</td>\n",
       "      <td>Application for Northwest Mainline Komie North...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Table 1 Summary Of Identified Residual Project...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729032.pdf</td>\n",
       "      <td>Application for Northwest Mainline Komie North...</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                  final_table_title  categories  \\\n",
       "0            7  Table 1 Summary Of Identified Residual Project...         1.0   \n",
       "1            9  Table 1 Summary Of Identified Residual Project...         1.0   \n",
       "2           11  Table 1 Summary Of Identified Residual Project...         1.0   \n",
       "3           13  Table 1 Summary Of Identified Residual Project...         1.0   \n",
       "4           15  Table 1 Summary Of Identified Residual Project...         1.0   \n",
       "\n",
       "   DataID_pdf                            Application title short Category  \n",
       "0  729032.pdf  Application for Northwest Mainline Komie North...    Table  \n",
       "1  729032.pdf  Application for Northwest Mainline Komie North...    Table  \n",
       "2  729032.pdf  Application for Northwest Mainline Komie North...    Table  \n",
       "3  729032.pdf  Application for Northwest Mainline Komie North...    Table  \n",
       "4  729032.pdf  Application for Northwest Mainline Komie North...    Table  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hearing = 'Application for Northwest Mainline Komie North Extension'\n",
    "komie_north = df[df['Application title short'] == hearing].reset_index(drop = True)\n",
    "komie_north.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

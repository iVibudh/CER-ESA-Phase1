{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed Terribly at this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code is divided into 2 parts <br>\n",
    "---> 1. Make Chunks based on the Postal Codes and Outlines: Here we are preparing a dataframe of all the file names that we read and try to divinde them into chunks based on the postal codes and the presence of outlines. <br>\n",
    "---> ---> 1 a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as p2\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the paths of the PDF scrapped \n",
    "\n",
    "path = 'F:/Environmental Baseline Data/Version 3/Data/PDF'\n",
    "pdfs = os.listdir(path)\n",
    "pdf_paths = [str(path) + '/' + str(x) for x in pdfs]\n",
    "len(pdf_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Chunks based on the Postal Codes and Outlines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code will generate a csv file with all the PDF nammes with the fillowing details: <br> - 'file_nos': just a number to indicate the file\n",
    "<br> - 'file_names': the name of the file (Postal Code.pdf)\n",
    "<br> - 'file_paths' : the path of the pdf file\n",
    "<br> - 'int_postals' : the integer value of the postal code\n",
    "<br> - 'chunk_nos': chunk_no based on the consectutive Postal Code\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 a. Postal to Int Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postal_to_int(Postal):\n",
    "    multiplier = 1\n",
    "    odd = 1\n",
    "    Postal_Int_Word = 0\n",
    "    Error_Message = \"Invalid Postal Code\"\n",
    "    \n",
    "    # Reversing the string \n",
    "    Postal = Postal[::-1] \n",
    "    \n",
    "    # Chcek for the length of the Postal Code\n",
    "    if not(len(Postal)==6):\n",
    "        return(Error_Message)\n",
    "    \n",
    "    for letter in list(str.strip(Postal)):\n",
    "        if odd%2 == 1:\n",
    "            # Check if it is an interger or not   \n",
    "            # If this is not an integer then exit\n",
    "            if not (str.isnumeric(letter)):\n",
    "                return(Error_Message)\n",
    "            \n",
    "            Postal_Int_Letter = multiplier * int(letter)\n",
    "            Postal_Int_Word = Postal_Int_Word + Postal_Int_Letter\n",
    "            \n",
    "            odd = odd + 1\n",
    "            multiplier = multiplier * 10\n",
    "            # print(letter, Postal_Int_Letter)\n",
    "            # print(Postal_Int_Word)\n",
    "        else:\n",
    "            # Check if it is a character or not\n",
    "            # If this is not a character then exit\n",
    "            if not (str.isalpha(letter)):\n",
    "                return(Error_Message)\n",
    "            \n",
    "            # ord('A') = 65\n",
    "            Postal_Int_Letter = multiplier * (ord(letter) - 65)\n",
    "            Postal_Int_Word = Postal_Int_Word + Postal_Int_Letter\n",
    "            \n",
    "            odd = odd + 1\n",
    "            multiplier = multiplier * 26\n",
    "            # print(letter, Postal_Int_Letter)\n",
    "            # print(Postal_Int_Word)\n",
    "            \n",
    "    return Postal_Int_Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# never used integer to Postal but I guess it would be useful \n",
    "# Also useful in validating if Postal to Int Function works \n",
    "\n",
    "def int_to_postal(Postal_Int_Word):\n",
    "    Postal_Int_Word_Rem = Postal_Int_Word\n",
    "    Postal = \"\"\n",
    "    odd = 0\n",
    "    Error_Message = \"Invalid Postal Code\"\n",
    "    \n",
    "    # Reversing the string \n",
    "    Postal = Postal[::-1] \n",
    " \n",
    "    while odd < 6:\n",
    "        if odd%2 == 0:\n",
    "            Postal_Int_Letter = Postal_Int_Word_Rem % 10\n",
    "            Postal = Postal + str(Postal_Int_Letter)\n",
    "            Postal_Int_Word_Rem = int(Postal_Int_Word_Rem/10)\n",
    "            odd = odd + 1\n",
    "\n",
    "        else:\n",
    "            Postal_Int_Letter = (Postal_Int_Word_Rem % 26) +65\n",
    "            Postal = Postal + chr(Postal_Int_Letter)\n",
    "            Postal_Int_Word_Rem = int(Postal_Int_Word_Rem/26)\n",
    "            odd = odd + 1\n",
    "            \n",
    "    # Accounts for 7 digit Postal Codes\n",
    "    if Postal_Int_Word_Rem > 0:\n",
    "        return(Error_Message)\n",
    "        \n",
    "    return Postal[::-1]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_nos = []\n",
    "file_names = []\n",
    "file_paths = []\n",
    "int_postals = []\n",
    "file_no = 1\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    # additional check to get rid of the string \"Thumb\"\n",
    "    if 'Thum' in pdf_path:\n",
    "        continue\n",
    "    \n",
    "    file_nos.append(file_no)\n",
    "    file_name = str(pdf_path.split('/')[-1])\n",
    "    file_names.append(file_name)\n",
    "    file_paths.append(pdf_path)\n",
    "    \n",
    "    postal = file_name[:-4]\n",
    "    int_postal = postal_to_int(postal)\n",
    "    int_postals.append(int_postal)\n",
    "    \n",
    "len(file_nos)\n",
    "len(file_names)\n",
    "len(file_paths)\n",
    "len(int_postals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 b. Check if Outline is present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "# Here we are not saving or extracting the Outlines yet\n",
    "# Here we are only checking if the extraction of the outline is possible or not \n",
    "outline_present = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    if 'Thum' in pdf_path:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pdfread = p2.PdfFileReader(pdf_path)\n",
    "        s = pdfread.outlines\n",
    "        len_s = len(s)\n",
    "    except:\n",
    "        outline_present.append(0) # Error in reading the outline\n",
    "        \n",
    "    if len_s > 0:\n",
    "        outline_present.append(1)\n",
    "    elif len_s == 0:\n",
    "        outline_present.append(0)\n",
    "    \n",
    "    # Error Code for s (=pdfraed.outlines) is -999\n",
    "    # the negative number allows exclusivity from the if and the elif conditions above\n",
    "    len_s = -999 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outline_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 c. Check if TOC is present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'F:/Environmental Baseline Data/Version 3/Data/HTML Images and Tables/A0U3G1/table-of-contents.txt'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the path of the TOC present\n",
    "path_Texts = []\n",
    "\n",
    "for path_pdf in pdf_paths:\n",
    "    if 'Thumb' in path_pdf:\n",
    "        continue\n",
    "    path_Text = path_pdf.replace(\" .pdf\", \"\")\n",
    "    if \".pdf\" in path_Text:\n",
    "        path_Text = path_pdf.replace(\".pdf\", \"\")\n",
    "    #print(path_Text)\n",
    "    path_Text = path_Text.replace(\"/PDF\", \"/HTML Images and Tables\")\n",
    "    path_Text = path_Text + \"/table-of-contents.txt\"\n",
    "    path_Texts.append(path_Text)\n",
    "    #print(path_Text)\n",
    "    \n",
    "len(path_Texts)\n",
    "path_Texts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML File does not exist for 189 files\n"
     ]
    }
   ],
   "source": [
    "# Here we are not saving or extracting the TOCs yet\n",
    "# Here we are only checking if the extraction of the TOC is possible or not \n",
    "TOC_present = []\n",
    "\n",
    "txt_path = \"F:/Environmental Baseline Data/Version 3/Data/Text/\"\n",
    "TOC_present = []\n",
    "txt_file_needed = []\n",
    "no_HTML = 0\n",
    "\n",
    "for path_Text in path_Texts:\n",
    "    try:\n",
    "        file_handle = open(path_Text,\"r\", encoding=\"utf8\")\n",
    "        if file_handle.mode == 'r':\n",
    "            contents = file_handle.read()\n",
    "            contents = contents.upper()\n",
    "            if 'TABLE OF CONTENTS' in contents:\n",
    "                TOC_present.append('1')\n",
    "            else:\n",
    "                TOC_present.append('0')\n",
    "                \n",
    "    except:\n",
    "        TOC_present.append('0')\n",
    "        no_HTML = no_HTML+1\n",
    "        \n",
    "        \n",
    "len(TOC_present)\n",
    "\n",
    "print(\"HTML File does not exist for {} files\".format(no_HTML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_nos</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>int_postals</th>\n",
       "      <th>outline_present</th>\n",
       "      <th>TOC_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C2.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A0U3G1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>52841</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_nos  file_names                                         file_paths  \\\n",
       "0         1  A0H8C0.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "1         1  A0H8C1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "2         1  A0H8C2.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "3         1  A0H8C3.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "4         1  A0U3G1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "\n",
       "   int_postals  outline_present TOC_present  \n",
       "0        20300                1           1  \n",
       "1        20301                1           0  \n",
       "2        20302                0           0  \n",
       "3        20303                0           0  \n",
       "4        52841                0           1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines = pd.DataFrame({'file_nos': file_nos, \n",
    "                            'file_names': file_names, \n",
    "                            'file_paths' : file_paths, \n",
    "                            'int_postals': int_postals, \n",
    "                            'outline_present': outline_present,\n",
    "                            'TOC_present': TOC_present})\n",
    "df_outlines.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 d. Make Chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defination of a Chunk: <br>\n",
    "    1 Each chunk of the pdf should have consecutive PDF files <br>\n",
    "    2 Each chunk of the files can have only one outline/TOC present  <br>\n",
    "    3 The first file of a chunk should be the file to have the outline/TOC present <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_nos = [1]\n",
    "chunk = 1\n",
    "consecutive_postal_codes = [0]\n",
    "\n",
    "for i in range(1, len(int_postals)):\n",
    "    new_chunk_found = 0\n",
    "    \n",
    "    # If conditions for new chunk based on consecutine postal codes - Ref 1 \n",
    "    if int_postals[i] != int_postals[i-1] + 1:\n",
    "        new_chunk_found = 1\n",
    "        chunk = chunk + 1\n",
    "        \n",
    "        \n",
    "    ## If conditions for new chunk based on outline present - Ref 2 and 3    \n",
    "    if outline_present[i] == 1 and outline_present[i-1] ==1 and new_chunk_found == 0: \n",
    "        new_chunk_found = 1\n",
    "        chunk = chunk + 1\n",
    "        \n",
    "    ## If conditions for new chunk based on TOC present - Ref 2 and 3    \n",
    "    if TOC_present[i] == 1 and TOC_present[i-1] ==1 and new_chunk_found == 0: \n",
    "        new_chunk_found = 1\n",
    "        chunk = chunk + 1\n",
    "        \n",
    "    ### Chunk not found based on any of the above conditions\n",
    "    chunk_nos.append(chunk)\n",
    "        \n",
    "    if int_postals[i] == int_postals[i-1] + 1:\n",
    "        consecutive_postal_codes.append(1)\n",
    "    else:\n",
    "        consecutive_postal_codes.append(0)\n",
    "        \n",
    "len(chunk_nos)\n",
    "len(consecutive_postal_codes)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_nos</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>int_postals</th>\n",
       "      <th>outline_present</th>\n",
       "      <th>TOC_present</th>\n",
       "      <th>consecutive_postals</th>\n",
       "      <th>chunk_nos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C2.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A0U3G1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>52841</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_nos  file_names                                         file_paths  \\\n",
       "0         1  A0H8C0.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "1         1  A0H8C1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "2         1  A0H8C2.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "3         1  A0H8C3.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "4         1  A0U3G1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "\n",
       "   int_postals  outline_present TOC_present  consecutive_postals  chunk_nos  \n",
       "0        20300                1           1                    0          1  \n",
       "1        20301                1           0                    1          2  \n",
       "2        20302                0           0                    1          2  \n",
       "3        20303                0           0                    1          2  \n",
       "4        52841                0           1                    0          3  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines['consecutive_postals'] = consecutive_postal_codes\n",
    "df_outlines['chunk_nos'] = chunk_nos\n",
    "df_outlines.head(5)\n",
    "df_outlines.to_csv(\"F:/Environmental Baseline Data/Version 3/Indices/Outline_Present.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract Chapters from PDFs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 a. By Outline Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functtion that runs recursively to extract the outlines of the PDF files\n",
    "def nested_is_instance_check(s, level, file_name, file_names, found_file_names, chapters, levels, pages):\n",
    "    level +=1\n",
    "    if isinstance(s, (int, list, float, complex)):\n",
    "        for x in s:\n",
    "            nested_is_instance_check(x, level, file_name, file_names, found_file_names, chapters, levels, pages)\n",
    "    elif level < 5:\n",
    "        chapters.extend([s.title])\n",
    "        levels.extend([level])\n",
    "        #it was observed that for a lot of PDF files we could not find the page number \n",
    "        # Hence, -999 is the error code added for those cases \n",
    "        page_error_flag = 0\n",
    "        try:\n",
    "            pages.extend([(pdfread.getDestinationPageNumber(s))])\n",
    "        except: \n",
    "            pages.extend([-999])\n",
    "            page_error_flag = 1\n",
    "        file_names.append([file_name])\n",
    "        \n",
    "        if page_error_flag != 1:\n",
    "            found_file_names.append([file_name])\n",
    "        else:\n",
    "            found_file_names.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_page_no(look_file_path, keyword):\n",
    "    object = p2.PdfFileReader(look_file_path)\n",
    "    \n",
    "    \n",
    "    # get number of pages\n",
    "    NumPages = object.getNumPages() \n",
    "    \n",
    "    # chapter_key_index is set as 1 because we dont want to search for\"0 Before First Chapter\"\n",
    "    # the array chapter_key_pages has first element 0 for the same reason\n",
    "    chapter_key_index = 1\n",
    "    chapter_key_page_Nos = [0]\n",
    "    Flag_TOC_over = 0\n",
    "    \n",
    "    # extract text and do the search\n",
    "    for i in range(0, NumPages):\n",
    "        PageObj = object.getPage(i)\n",
    "        #print(\"this is page \" + str(i)) \n",
    "        Text = PageObj.extractText()\n",
    "        Text = Text.lower()\n",
    "        Text = Text.replace(\"\\n\", \"\")\n",
    "        # Text = Text\n",
    "        # print (Text)\n",
    "            \n",
    "        #ResSearch = re.search(chapter_keys[chapter_key_index], Text)\n",
    "        key = keyword.lower()\n",
    "        if (key in Text):\n",
    "            return i, str(look_file_path.split('/')[-1])\n",
    "        \n",
    "    return(-999, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 1\n",
      "stage 1\n",
      "stage 1\n"
     ]
    }
   ],
   "source": [
    "# Variables for Initialization of the data frame for Index 4 - Chapters.csv\n",
    "file_names = []\n",
    "found_file_names = []\n",
    "chapters = []\n",
    "levels = []\n",
    "pages = []\n",
    "all_df_chapters = pd.DataFrame({'file_names': file_names, 'found_file_names': found_file_names, 'chapters': chapters, 'pages' : pages, 'levels' : levels})\n",
    "\n",
    "for current_chunk in range(10,12):#chunk+1):\n",
    "    current_df_outlines = df_outlines[df_outlines.chunk_nos == current_chunk]\n",
    "    \n",
    "    chunk_has_outline = 0\n",
    "    chunk_noOutline_hasTOC = 0\n",
    "    \n",
    "    file_name_containing_index = '0'\n",
    "    \n",
    "    p_file_names = []\n",
    "    p_found_file_names = []\n",
    "    p_chapters = []\n",
    "    p_levels = []\n",
    "    p_pages = []\n",
    "    level = 0\n",
    "    # Going through all the PDFs - Chunk by Chunk\n",
    "    for i in range(len(current_df_outlines)):\n",
    "        # First file in the chunk has Outline \n",
    "        if current_df_outlines.iloc[i]['outline_present'] == 1:\n",
    "            chunk_has_outline = 1\n",
    "            print(\"stage 1\")\n",
    "            pdfread = p2.PdfFileReader(current_df_outlines.iloc[i]['file_paths'])\n",
    "            s = pdfread.outlines\n",
    "            \n",
    "            nested_is_instance_check(s, \n",
    "                                     level, \n",
    "                                     current_df_outlines.iloc[i]['file_names'], \n",
    "                                     p_file_names, p_found_file_names, \n",
    "                                     p_chapters, p_levels, p_pages)\n",
    "            file_name_containing_index = current_df_outlines.iloc[i]['file_names']\n",
    "            continue\n",
    "            \n",
    "        if count_occorances(p_pages, -999) > 1 and chunk_has_outline == 1:\n",
    "            print(\"stage 2: file is {}\".format(current_df_outlines.iloc[i]['file_names']))\n",
    "            start_flag = 0\n",
    "            page_no = -999\n",
    "            #print(p_pages)\n",
    "            for j in range(len(p_chapters)):\n",
    "                if p_pages[j] >= 0 and p_levels[j] < 5: # probably could have also used p_pages[j] >= - 998\n",
    "                    print(\"start flag is on\")\n",
    "                    start_flag = 1\n",
    "                    continue\n",
    "                \n",
    "                if start_flag != 1:\n",
    "                    continue\n",
    "                    \n",
    "                if start_flag == 1 and p_pages[j] <= 0 and p_levels[j] < 5:\n",
    "                    print(\"stage 3: finding page no for {} with page{}\".format(p_chapters[j], p_pages[j]))\n",
    "                    page_no, found_file_name = find_page_no(current_df_outlines.iloc[i]['file_paths'], \n",
    "                                                            p_chapters[j])\n",
    "                    p_pages[j] = page_no\n",
    "                    p_found_file_names = current_df_outlines.iloc[i]['file_names']\n",
    "                    \n",
    "                if page_no == -999 and p_levels[j] < 5:\n",
    "                    print(\"Not found\")\n",
    "                    break # if the first keyword is not found then dont look any further\n",
    "                else:\n",
    "                    print(\"New Found \")\n",
    "            \n",
    "    df_chapters = pd.DataFrame({'file_names': p_file_names, 'found_file_names': p_found_file_names, 'chapters': p_chapters, 'pages' : p_pages, 'levels' : p_levels})\n",
    "    all_df_chapters = pd.concat([all_df_chapters, df_chapters])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlines['outline_present'] = outline_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>found_file_names</th>\n",
       "      <th>chapters</th>\n",
       "      <th>pages</th>\n",
       "      <th>levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Environmental Impact Assessment and Mitigation...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Project Background</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Regulatory Setting</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Figure 13.1-1EnCana Ekwan Pipeline</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[A0H8C1.pdf]</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>Scope of Environmental Assessment</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_names found_file_names  \\\n",
       "0  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "1  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "2  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "3  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "4  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "5  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "6  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "7  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "8  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "9  [A0H8C1.pdf]       A0H8C3.pdf   \n",
       "\n",
       "                                            chapters  pages  levels  \n",
       "0  Environmental Impact Assessment and Mitigation... -999.0     2.0  \n",
       "1                                       Introduction -999.0     3.0  \n",
       "2                                 Project Background -999.0     4.0  \n",
       "3                                 Regulatory Setting -999.0     4.0  \n",
       "4                                                      -1.0     5.0  \n",
       "5                                                      -1.0     6.0  \n",
       "6                                                      -1.0     7.0  \n",
       "7                                                      -1.0     8.0  \n",
       "8                 Figure 13.1-1EnCana Ekwan Pipeline   -1.0     9.0  \n",
       "9                  Scope of Environmental Assessment -999.0     4.0  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################################################\n",
    "########## We might need to think of a better way to extract important chapters ##########\n",
    "##########  df.chapters.levels < 5, is not teh best way ##################################\n",
    "##########################################################################################\n",
    "#all_df_chapters = all_df_chapters[all_df_chapters.chapters is not None]  #  and all_df_chapters.levels < 5]\n",
    "all_df_chapters.head(10)\n",
    "all_df_chapters.to_csv(\"F:/Environmental Baseline Data/Version 3/Indices/New try Index 4 (Outlines)- Chapters.csv\")\n",
    "\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Extraction by TOC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functtion that runs recursively to extract the outlines of the PDF files\n",
    "def extract_TOC_page_numbers(path_Text):\n",
    "    with open(path_Text) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        raw_TOC_text = data['raw_text'] #currently the array has a lot of strings which are not main headers \n",
    "        if len(raw_TOC_text) < 1:\n",
    "            print(\"No TOC Found\")\n",
    "    \n",
    "    \n",
    "    chapter_keys = [\"0 Before First Chapter\"] \n",
    "    Flag_Appendix_Found = 0\n",
    "    for head in raw_TOC_text:\n",
    "        head = head.strip()\n",
    "        head = re.sub(' +', ' ',head)\n",
    "        if head[0].isdigit() and len(head) > 5: # assuming all the headings in the TOC are numbered\n",
    "            head = head_clean(head) # removing soo many filler '.' in the string\n",
    "            \n",
    "            ##########################################\n",
    "            # Here, we night need to set a threshold (On the number of dots) value depending on the PDF and its TOC \n",
    "            ##########################################\n",
    "            \n",
    "            threshold = 2\n",
    "            if head.count('.') < threshold:\n",
    "                head = head.strip()\n",
    "                chapter_keys.append(head)\n",
    "                \n",
    "            # Here we check for Appendix \n",
    "        if \"Appendix\" in head or \"APPENDIX\" in head:\n",
    "            chapter_keys.append(\"99 Appendix\")\n",
    "            Flag_Appendix_Found = 1\n",
    "            break\n",
    "                \n",
    "    if Flag_Appendix_Found == 0:\n",
    "        chapter_keys.append(\"99 Appendix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for Initialization of the data frame for Index 4 - Chapters.csv\n",
    "file_names = []\n",
    "found_file_names = []\n",
    "chapters = []\n",
    "levels = []\n",
    "pages = []\n",
    "all_df_chapters = pd.DataFrame({'file_names': file_names, 'found_file_names': found_file_names, 'chapters': chapters, 'pages' : pages, 'levels' : levels})\n",
    "\n",
    "for current_chunk in range(10,12):#chunk+1):\n",
    "    current_df_outlines = df_outlines[df_outlines.chunk_nos == current_chunk]\n",
    "    \n",
    "    chunk_has_outline = 0\n",
    "    chunk_noOutline_hasTOC = 0\n",
    "    \n",
    "    file_name_containing_index = '0'\n",
    "    \n",
    "    p_file_names = []\n",
    "    p_found_file_names = []\n",
    "    p_chapters = []\n",
    "    p_levels = []\n",
    "    p_pages = []\n",
    "    level = 0\n",
    "    # Going through all the PDFs - Chunk by Chunk\n",
    "    for i in range(len(current_df_outlines)):\n",
    "        # First file in the chunk has Outline \n",
    "        if current_df_outlines.iloc[i]['outline_present'] == 1:\n",
    "            chunk_has_outline = 1\n",
    "            print(\"stage 1\")\n",
    "            pdfread = p2.PdfFileReader(current_df_outlines.iloc[i]['file_paths'])\n",
    "            s = pdfread.outlines\n",
    "            \n",
    "            nested_is_instance_check(s, \n",
    "                                     level, \n",
    "                                     current_df_outlines.iloc[i]['file_names'], \n",
    "                                     p_file_names, p_found_file_names, \n",
    "                                     p_chapters, p_levels, p_pages)\n",
    "            file_name_containing_index = current_df_outlines.iloc[i]['file_names']\n",
    "            continue\n",
    "            \n",
    "        if count_occorances(p_pages, -999) > 1 and chunk_has_outline == 1:\n",
    "            print(\"stage 2: file is {}\".format(current_df_outlines.iloc[i]['file_names']))\n",
    "            start_flag = 0\n",
    "            page_no = -999\n",
    "            #print(p_pages)\n",
    "            for j in range(len(p_chapters)):\n",
    "                if p_pages[j] >= 0 and p_levels[j] < 5: # probably could have also used p_pages[j] >= - 998\n",
    "                    print(\"start flag is on\")\n",
    "                    start_flag = 1\n",
    "                    continue\n",
    "                \n",
    "                if start_flag != 1:\n",
    "                    continue\n",
    "                    \n",
    "                if start_flag == 1 and p_pages[j] <= 0 and p_levels[j] < 5:\n",
    "                    print(\"stage 3: finding page no for {} with page{}\".format(p_chapters[j], p_pages[j]))\n",
    "                    page_no, found_file_name = find_page_no(current_df_outlines.iloc[i]['file_paths'], \n",
    "                                                            p_chapters[j])\n",
    "                    p_pages[j] = page_no\n",
    "                    p_found_file_names = current_df_outlines.iloc[i]['file_names']\n",
    "                    \n",
    "                if page_no == -999 and p_levels[j] < 5:\n",
    "                    print(\"Not found\")\n",
    "                    break # if the first keyword is not found then dont look any further\n",
    "                else:\n",
    "                    print(\"New Found \")\n",
    "            \n",
    "    df_chapters = pd.DataFrame({'file_names': p_file_names, 'found_file_names': p_found_file_names, 'chapters': p_chapters, 'pages' : p_pages, 'levels' : p_levels})\n",
    "    all_df_chapters = pd.concat([all_df_chapters, df_chapters])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont think I needed this function \n",
    "def count_occorances(lst, x):\n",
    "    count = 0\n",
    "    for ele in lst:\n",
    "        if ele == x:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A0H8C2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A0U3G1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_names\n",
       "0  A0H8C0.pdf\n",
       "1  A0H8C1.pdf\n",
       "2  A0H8C2.pdf\n",
       "3  A0H8C3.pdf\n",
       "4  A0U3G1.pdf"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines[[\"file_names\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_nos</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>int_postals</th>\n",
       "      <th>outline_present</th>\n",
       "      <th>TOC_present</th>\n",
       "      <th>consecutive_postals</th>\n",
       "      <th>chunk_nos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_nos  file_names                                         file_paths  \\\n",
       "0         1  A0H8C0.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "\n",
       "   int_postals  outline_present TOC_present  consecutive_postals  chunk_nos  \n",
       "0        20300                1           1                    0          1  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_names\n",
       "0  A0H8C0.pdf"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines[:1][[\"file_names\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outline_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outline_present\n",
       "0                1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-ab9a95bc71f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_outlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"outline_present\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mdf_outlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutline_present\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "df_outlines[:1][[\"outline_present\"]]\n",
    "(df_outlines[:1].values([outline_present]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines.iloc[0]['outline_present']\n",
    "df_outlines.iloc[0]['outline_present'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df_outlines = df_outlines[df_outlines.chunk_nos == 3]\n",
    "type(current_df_outlines.file_paths)\n",
    "chunk_file_paths = current_df_outlines.file_paths\n",
    "chunk_size = len(chunk_file_paths)\n",
    "chunk_size\n",
    "len(current_df_outlines.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

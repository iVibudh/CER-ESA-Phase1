{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as p2\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# from goto import goto, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the paths of the PDF scrapped \n",
    "\n",
    "path = 'F:/Environmental Baseline Data/Version 3/Data/PDF'\n",
    "pdfs = os.listdir(path)\n",
    "pdf_paths = [str(path) + '/' + str(x) for x in pdfs]\n",
    "len(pdf_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Outlines Based on the Postal Codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code will generate a csv file with all the PDF nammes with the fillowing details: <br> - 'file_nos': just a number to indicate the file\n",
    "<br> - 'file_names': the name of the file (Postal Code.pdf)\n",
    "<br> - 'file_paths' : the path of the pdf file\n",
    "<br> - 'int_postals' : the integer value of the postal code\n",
    "<br> - 'chunk_nos': chunk_no based on the consectutive Postal Code\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postal to Int Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postal_to_int(Postal):\n",
    "    multiplier = 1\n",
    "    odd = 1\n",
    "    Postal_Int_Word = 0\n",
    "    Error_Message = \"Invalid Postal Code\"\n",
    "    \n",
    "    # Reversing the string \n",
    "    Postal = Postal[::-1] \n",
    "    \n",
    "    # Chcek for the length of the Postal Code\n",
    "    if not(len(Postal)==6):\n",
    "        return(Error_Message)\n",
    "    \n",
    "    for letter in list(str.strip(Postal)):\n",
    "        if odd%2 == 1:\n",
    "            # Check if it is an interger or not   \n",
    "            # If this is not an integer then exit\n",
    "            if not (str.isnumeric(letter)):\n",
    "                return(Error_Message)\n",
    "            \n",
    "            Postal_Int_Letter = multiplier * int(letter)\n",
    "            Postal_Int_Word = Postal_Int_Word + Postal_Int_Letter\n",
    "            \n",
    "            odd = odd + 1\n",
    "            multiplier = multiplier * 10\n",
    "            # print(letter, Postal_Int_Letter)\n",
    "            # print(Postal_Int_Word)\n",
    "        else:\n",
    "            # Check if it is a character or not\n",
    "            # If this is not a character then exit\n",
    "            if not (str.isalpha(letter)):\n",
    "                return(Error_Message)\n",
    "            \n",
    "            # ord('A') = 65\n",
    "            Postal_Int_Letter = multiplier * (ord(letter) - 65)\n",
    "            Postal_Int_Word = Postal_Int_Word + Postal_Int_Letter\n",
    "            \n",
    "            odd = odd + 1\n",
    "            multiplier = multiplier * 26\n",
    "            # print(letter, Postal_Int_Letter)\n",
    "            # print(Postal_Int_Word)\n",
    "            \n",
    "    return Postal_Int_Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# never used integer to Postal but I guess it would be useful \n",
    "# Also useful in validating if Postal to Int Function works \n",
    "\n",
    "def int_to_postal(Postal_Int_Word):\n",
    "    Postal_Int_Word_Rem = Postal_Int_Word\n",
    "    Postal = \"\"\n",
    "    odd = 0\n",
    "    Error_Message = \"Invalid Postal Code\"\n",
    "    \n",
    "    # Reversing the string \n",
    "    Postal = Postal[::-1] \n",
    " \n",
    "    while odd < 6:\n",
    "        if odd%2 == 0:\n",
    "            Postal_Int_Letter = Postal_Int_Word_Rem % 10\n",
    "            Postal = Postal + str(Postal_Int_Letter)\n",
    "            Postal_Int_Word_Rem = int(Postal_Int_Word_Rem/10)\n",
    "            odd = odd + 1\n",
    "\n",
    "        else:\n",
    "            Postal_Int_Letter = (Postal_Int_Word_Rem % 26) +65\n",
    "            Postal = Postal + chr(Postal_Int_Letter)\n",
    "            Postal_Int_Word_Rem = int(Postal_Int_Word_Rem/26)\n",
    "            odd = odd + 1\n",
    "            \n",
    "    # Accounts for 7 digit Postal Codes\n",
    "    if Postal_Int_Word_Rem > 0:\n",
    "        return(Error_Message)\n",
    "        \n",
    "    return Postal[::-1]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_nos = []\n",
    "file_names = []\n",
    "file_paths = []\n",
    "int_postals = []\n",
    "file_no = 1\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    # additional check to get rid of the string \"Thumb\"\n",
    "    if 'Thum' in pdf_path:\n",
    "        continue\n",
    "    \n",
    "    file_nos.append(file_no)\n",
    "    file_name = str(pdf_path.split('/')[-1])\n",
    "    file_names.append(file_name)\n",
    "    file_paths.append(pdf_path)\n",
    "    \n",
    "    postal = file_name[:-4]\n",
    "    int_postal = postal_to_int(postal)\n",
    "    int_postals.append(int_postal)\n",
    "    \n",
    "len(file_nos)\n",
    "len(file_names)\n",
    "len(file_paths)\n",
    "len(int_postals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_nos = []\n",
    "chunk = 0\n",
    "last_postal = int_postals[0]\n",
    "\n",
    "for int_postal in int_postals:\n",
    "    if int_postal == last_postal + 1:\n",
    "        chunk_nos.append(chunk)\n",
    "    else:\n",
    "        chunk = chunk +1\n",
    "        chunk_nos.append(chunk)\n",
    "    last_postal = int_postal\n",
    "    \n",
    "len(chunk_nos)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_nos</th>\n",
       "      <th>file_names</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>int_postals</th>\n",
       "      <th>chunk_nos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C0.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C2.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A0H8C3.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>20303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A0U3G1.pdf</td>\n",
       "      <td>F:/Environmental Baseline Data/Version 3/Data/...</td>\n",
       "      <td>52841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_nos  file_names                                         file_paths  \\\n",
       "0         1  A0H8C0.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "1         1  A0H8C1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "2         1  A0H8C2.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "3         1  A0H8C3.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "4         1  A0U3G1.pdf  F:/Environmental Baseline Data/Version 3/Data/...   \n",
       "\n",
       "   int_postals  chunk_nos  \n",
       "0        20300          1  \n",
       "1        20301          1  \n",
       "2        20302          1  \n",
       "3        20303          1  \n",
       "4        52841          2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlines = pd.DataFrame({'file_nos': file_nos, 'file_names': file_names, 'file_paths' : file_paths, 'int_postals': int_postals, 'chunk_nos': chunk_nos})\n",
    "df_outlines.head(5)\n",
    "df_outlines.to_csv(\"F:/Environmental Baseline Data/Version 3/Indices/Outline_Present.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract Chapters (Outline level < 4) from all PDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functtion that runs recursively to extract the outlines of the PDF files\n",
    "def nested_is_instance_check(s, level, file_name, file_names_ch, chapters, levels, pages):\n",
    "    level +=1\n",
    "    if isinstance(s, (int, list, float, complex)):\n",
    "        for x in s:\n",
    "            nested_is_instance_check(x, level, file_name, file_names_ch, chapters, levels, pages)\n",
    "    else:\n",
    "        chapters.extend([s.title])\n",
    "        levels.extend([level])\n",
    "        #it was observed that for a lot of PDF files we could not find the page number \n",
    "        # Hence, -999 is the error code added for those cases \n",
    "        try:\n",
    "            pages.extend([str(pdfread.getDestinationPageNumber(s))])\n",
    "        except: \n",
    "            pages.extend([-999])\n",
    "        file_names_ch.append([file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occorances(lst, x):\n",
    "    count = 0\n",
    "    for ele in lst:\n",
    "        if ele == x:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df_outlines = df_outlines[df_outlines.chunk_nos == 3]\n",
    "type(current_df_outlines.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file A0H8C0.pdf might carry on to other PDFs\n",
      "Probably Repeated Outline found at file A0H8C1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1T0F5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1T0F7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1T0F8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1T0G0.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1T0G1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1Y9H5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1Y9H6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1Y9H7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A1Y9H8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A2F4L2.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A2F4L3.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A2F4L4.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A2F4L7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A2F4L9.pdf\n",
      "Repeatition confirmed\n",
      "This file A3E2X6.pdf might carry on to other PDFs\n",
      "Probably Repeated Outline found at file A3E2X7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2X8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2X9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Y0.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Y1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Y2.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Y4.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Y5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z3.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z4.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E2Z8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E3A1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E3A6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E3A7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E3A8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3E3A9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2J5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2J7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2J9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2K2.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2K4.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2K6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2K9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2L1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2L6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2L7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2L8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2L9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2R6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2R7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A3S2R8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A8K5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A8K6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A8K9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A8L0.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A8L9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9E1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9F9.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G0.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G1.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G2.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G3.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G4.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G6.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G7.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A5A9G8.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A6T2H2.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A6T2H5.pdf\n",
      "Repeatition confirmed\n",
      "Probably Repeated Outline found at file A6T2H6.pdf\n",
      "Repeatition confirmed\n"
     ]
    }
   ],
   "source": [
    "outline_present = []\n",
    "outline_not_present_but_TOC_present = []\n",
    "file_names = []\n",
    "\n",
    "# Variables for Initialization of the data frame for Index 4 - Chapters.csv\n",
    "file_names_ch = []\n",
    "chapters = []\n",
    "levels = []\n",
    "pages = []\n",
    "all_df_chapters = pd.DataFrame({'file_names': file_names_ch, 'chapters': chapters, 'pages' : pages, 'levels' : levels})\n",
    "\n",
    "\n",
    "for current_chunk in range(0, chunk+1-80):\n",
    "    current_df_outlines = df_outlines[df_outlines.chunk_nos == current_chunk]\n",
    "    \n",
    "    # Variables for Index 4 - Chapters.csv for each Chunk\n",
    "    file_names_ch = []\n",
    "    chapters = []\n",
    "    levels = []\n",
    "    pages = []\n",
    "    \n",
    "    \n",
    "    last_file_names_ch = []\n",
    "    last_chapters = []\n",
    "    last_levels = []\n",
    "    last_pages = []\n",
    "    \n",
    "    # Going Chunk by Chunk \n",
    "    # We define chunk as all pdfs that have consecutive Postal Codes \n",
    "    for pdf_path in current_df_outlines.file_paths:\n",
    "        \n",
    "        # Variables for Index 4 - Chapters.csv for each Chunk\n",
    "        p_file_names_ch = []\n",
    "        p_chapters = []\n",
    "        p_levels = []\n",
    "        p_pages = []\n",
    "               \n",
    "        #Initializations are done here \n",
    "        file_name = str(pdf_path.split('/')[-1])\n",
    "        file_names.append(file_name)\n",
    "        outline_p = 0\n",
    "        \n",
    "        ### Try getting the outline first \n",
    "        try:\n",
    "            pdfread = p2.PdfFileReader(pdf_path)\n",
    "            s = pdfread.outlines\n",
    "            len_s = len(s)\n",
    "        except:\n",
    "            len_s = -99\n",
    "        \n",
    "        if len_s > 0:\n",
    "            level = 0\n",
    "            outline_p = 1\n",
    "            outline_present.append(1) # 1 Indicating that the outline is present \n",
    "            outline_not_present_but_TOC_present.append(0)\n",
    "            nested_is_instance_check(s, level, file_name, p_file_names_ch, p_chapters, p_levels, p_pages)\n",
    "        elif len_s == 0:\n",
    "            outline_p = 0\n",
    "            outline_present.append(0)\n",
    "        else:\n",
    "            outline_p = -1\n",
    "            outline_present.append(-1)\n",
    "    \n",
    "              \n",
    "        ## If Outline is present check if the last pdf had the same Outline\n",
    "        if outline_p > 0:\n",
    "            if count_occorances(pages, -999) > 1:\n",
    "            ###################################################\n",
    "            ############ Write a fn  to look for the same stuff in other pdf files. \n",
    "            ############\n",
    "        \n",
    "                # look if other PDFs have outlines too\n",
    "                if p_chapters == last_chapters:\n",
    "                    print(\"Repeatition confirmed\")\n",
    "                    ### Retain the chapter names from last chapter and keep moving \n",
    "                    chapters_might_modify = 1\n",
    "                    \n",
    "                ###################################################\n",
    "                ############ Write a fn  to make it (page_nos) consistent\n",
    "                ############\n",
    "                \n",
    "                else:\n",
    "                    print(\"This file {} might carry on to other PDFs\".format(file_name))\n",
    "                    \n",
    "            else:\n",
    "                file_names_ch.extend(p_file_names_ch)\n",
    "                chapters.extend(p_chapters)\n",
    "                levels.extend(p_levels)\n",
    "                pages.extend(p_pages)\n",
    "                last_chapters = []\n",
    "                chapters_might_modify = 0\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "           \n",
    "                    \n",
    "        ## If outline is not present then let's see if theer are other ways to check             \n",
    "        else:\n",
    "            ###################################################\n",
    "            ############ Use Other methods to extract the TOC \n",
    "            ### 1. Check in the chunk for help \n",
    "            ### 2. Check for PDF to HTMl Method to extract Table of contents \n",
    "            # if TOC Present then outline_not_present_but_TOC_present.append(1)\n",
    "            \n",
    "            outline_not_present_but_TOC_present.append(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "        if switch_last_chapter == 1:\n",
    "            last_chapters = p_chapters\n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "        # Error Code for s (=pdfraed.outlines) is -99\n",
    "        # the negative number allows exclusivity from the if and the elif conditions above\n",
    "        # so the previous value is not affecting the next itteration in case the try block \n",
    "        # does not complete all its operations \n",
    "        len_s = -99\n",
    "        switch_last_chapter = 1\n",
    "            \n",
    "            \n",
    "    # change this based on the above mentioned if statements \n",
    "    df_chapters = pd.DataFrame({'file_names': file_names_ch, 'chapters': chapters, 'pages' : pages, 'levels' : levels})\n",
    "    all_df_chapters = pd.concat([all_df_chapters, df_chapters])\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outline_present)\n",
    "len(file_names)\n",
    "len(df_outlines['file_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-c0d48ff402ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_outlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outline_present'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutline_present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3471\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3472\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3548\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3549\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3550\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3733\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3734\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "df_outlines['outline_present'] = outline_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "########## We might need to think of a better way to extract important chapters ##########\n",
    "##########  df.chapters.levels < 5, is not teh best way ##################################\n",
    "##########################################################################################\n",
    "all_df_chapters = all_df_chapters[all_df_chapters.chapters is not None  and all_df_chapters.levels < 5]\n",
    "all_df_chapters.head(5)\n",
    "all_df_chapters.to_csv(\"F:/Environmental Baseline Data/Version 3/Indices/Index 4 (Outlines)- Chapters.csv\")\n",
    "\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arra = [1, 2, 3]\n",
    "arr = [1, 2, 3]\n",
    "if arr == arra:\n",
    "    print(\"yes\")\n",
    "arra.extend(arr)\n",
    "arra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
